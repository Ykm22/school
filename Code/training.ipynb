{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "import sklearn\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Facultate\\anul_3\\ELL\\Code\\Datasets\\ADNI\\ADNI1\n",
      "d:\\Facultate\\anul_3\\ELL\\Code\\Datasets\\ADNI\\ADNI1\\Images\n",
      "d:\\Facultate\\anul_3\\ELL\\Code\\Datasets\\ADNI\\ADNI1\\SegmentationMasks\n",
      "d:\\Facultate\\anul_3\\ELL\\Code\\Datasets\\ADNI\\ADNI1\\ADNI1_T1_Imgs_CN-MCI-AD_5_18_2024.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = Path(os.getcwd()) / \"Datasets\" / \"ADNI\" / \"ADNI1\"\n",
    "print(dataset_dir)\n",
    "\n",
    "imgs_dir = dataset_dir / \"Images\"\n",
    "masks_dir = dataset_dir / \"SegmentationMasks\"\n",
    "store_dir = dataset_dir / \"InputImages\"\n",
    "input_dir = store_dir\n",
    "\n",
    "print(imgs_dir)\n",
    "print(masks_dir)\n",
    "\n",
    "csv_files = dataset_dir.glob(\"**/*.csv\")\n",
    "for csv_file in csv_files:\n",
    "    csv_data = csv_file\n",
    "    \n",
    "print(csv_data)\n",
    "df = pd.read_csv(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Acq Date</th>\n",
       "      <th>Format</th>\n",
       "      <th>Downloaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I118692</td>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>85</td>\n",
       "      <td>m06</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled_2</td>\n",
       "      <td>Processed</td>\n",
       "      <td>11/02/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>5/17/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I64025</td>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>86</td>\n",
       "      <td>m12</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>5/25/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>5/18/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I118671</td>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>85</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled_2</td>\n",
       "      <td>Processed</td>\n",
       "      <td>4/18/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>5/18/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I123685</td>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>87</td>\n",
       "      <td>m24</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>7/23/2008</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>5/17/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I150177</td>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>88</td>\n",
       "      <td>m36</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>5/22/2009</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>5/17/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I40966</td>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>85</td>\n",
       "      <td>m06</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>11/02/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>5/17/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I45108</td>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>85</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>4/18/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>5/18/2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image Data ID     Subject Group Sex  Age Visit Modality  \\\n",
       "0       I118692  002_S_0295    CN   M   85   m06      MRI   \n",
       "1        I64025  002_S_0295    CN   M   86   m12      MRI   \n",
       "2       I118671  002_S_0295    CN   M   85    sc      MRI   \n",
       "3       I123685  002_S_0295    CN   M   87   m24      MRI   \n",
       "4       I150177  002_S_0295    CN   M   88   m36      MRI   \n",
       "5        I40966  002_S_0295    CN   M   85   m06      MRI   \n",
       "6        I45108  002_S_0295    CN   M   85    sc      MRI   \n",
       "\n",
       "                                  Description       Type    Acq Date Format  \\\n",
       "0  MPR; GradWarp; B1 Correction; N3; Scaled_2  Processed  11/02/2006  NiFTI   \n",
       "1    MPR; GradWarp; B1 Correction; N3; Scaled  Processed   5/25/2007  NiFTI   \n",
       "2  MPR; GradWarp; B1 Correction; N3; Scaled_2  Processed   4/18/2006  NiFTI   \n",
       "3    MPR; GradWarp; B1 Correction; N3; Scaled  Processed   7/23/2008  NiFTI   \n",
       "4    MPR; GradWarp; B1 Correction; N3; Scaled  Processed   5/22/2009  NiFTI   \n",
       "5    MPR; GradWarp; B1 Correction; N3; Scaled  Processed  11/02/2006  NiFTI   \n",
       "6    MPR; GradWarp; B1 Correction; N3; Scaled  Processed   4/18/2006  NiFTI   \n",
       "\n",
       "  Downloaded  \n",
       "0  5/17/2024  \n",
       "1  5/18/2024  \n",
       "2  5/18/2024  \n",
       "3  5/17/2024  \n",
       "4  5/17/2024  \n",
       "5  5/17/2024  \n",
       "6  5/18/2024  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(acq_date):\n",
    "    parsed_date = datetime.strptime(acq_date, f\"%m/%d/%Y\")\n",
    "    return parsed_date.strftime(f\"%Y-%m-%d\")\n",
    "\n",
    "def read_img(parent_dir, subject, date):\n",
    "    input_img_path = parent_dir / f\"{subject}__{date}.nii\"\n",
    "    if not os.path.exists(input_img_path):\n",
    "        return None\n",
    "    input_img = nib.load(input_img_path).get_fdata()\n",
    "    return input_img\n",
    "    # print(input_img.shape)\n",
    "    # plot_axes(input_img, 130)    \n",
    "\n",
    "def plot_16_coronal_slices(img, slice_number):\n",
    "    slices = []\n",
    "    for slice_no in range(slice_number - 7, slice_number + 9):\n",
    "        slices.append(img[:, slice_no, :])# coronal\n",
    "\n",
    "    # print(f\"coronal shape = {slice2.shape}\")\n",
    "    plt.figure()\n",
    "\n",
    "    fig, axes = plt.subplots(4, 4)\n",
    "\n",
    "    plt.xticks([])  # Hide x axis ticks and labels\n",
    "    plt.yticks([])  # Hide y axis ticks and labels\n",
    "\n",
    "    # for ax in axes:\n",
    "        # ax.set_xticks([])\n",
    "        # ax.set_yticks([])\n",
    "\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            axes[i][j].imshow(slices[i * 4 + j].T, cmap='gray', origin='lower')\n",
    "            # axes[i][j].set_title(f\"slice {i * 4 + j + 1}\")\n",
    "    plt.tight_layout\n",
    "    plt.show()\n",
    "\n",
    "def read_image(path):\n",
    "    input_img = nib.load(path).get_fdata()\n",
    "    return input_img\n",
    "\n",
    "def separate_16_coronal_slices(img, slice_number):\n",
    "    slices = []\n",
    "    for slice_no in range(slice_number - 14, slice_number + 16):\n",
    "        slices.append(img[:, slice_no, :]) # coronal\n",
    "    return slices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Dataset for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "113\n",
      "600\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "img_paths = []\n",
    "labels = []\n",
    "additional_data = [] # (sex, age)\n",
    "\n",
    "limit = 300\n",
    "cn_limit = 0\n",
    "mci_limit = 0\n",
    "ad_limit = 0\n",
    "\n",
    "input_shapes = {\n",
    "    (256, 256, 166) : 128,\n",
    "    # (192, 192, 160) : {86},\n",
    "    # (240, 256, 160) : {128}\n",
    "}\n",
    "\n",
    "i = 0\n",
    "for index, row in df.iterrows():\n",
    "    group = row[\"Group\"]\n",
    "    # print(group)\n",
    "    # print(count)\n",
    "    \n",
    "    subject = row[\"Subject\"]\n",
    "    date = convert_date(row[\"Acq Date\"])\n",
    "    input_img = read_img(input_dir, subject, date)\n",
    "    \n",
    "    # if image doesn't exist or doesn't follow shape criteria don't add it\n",
    "    if input_img is None or input_img.shape not in input_shapes.keys():\n",
    "        continue\n",
    "\n",
    "    # if i == 1:\n",
    "    #     plot_axes(input_img, input_shapes[input_img.shape])\n",
    "    #     plot_16_coronal_slices(input_img, input_shapes[input_img.shape])\n",
    "    # i = i + 1\n",
    "    if group == \"MCI\":\n",
    "        continue\n",
    "    \n",
    "    if group == \"CN\":\n",
    "        if cn_limit == limit:\n",
    "            continue\n",
    "        cn_limit = cn_limit + 1\n",
    "    else:\n",
    "        if ad_limit == limit:\n",
    "            continue\n",
    "        ad_limit = ad_limit + 1 \n",
    "\n",
    "    sex = 0 if row[\"Sex\"] == 'M' else 1\n",
    "    age = row[\"Age\"]\n",
    "    additional_data.append((sex, age))\n",
    "    # print(additional_data)\n",
    "\n",
    "    input_img_path = input_dir / f\"{subject}__{date}.nii\"\n",
    "    img_paths.append(input_img_path)\n",
    "    labels.append(row[\"Group\"])\n",
    "\n",
    "\n",
    "num_cn = 300\n",
    "num_mci = 187\n",
    "num_ad = 187\n",
    "\n",
    "upsample_count = num_cn - num_ad\n",
    "already_inserted = []\n",
    "\n",
    "for idx, data in enumerate(img_paths):\n",
    "    group = labels[idx]\n",
    "    if group == 'AD' and upsample_count > 0:\n",
    "        upsample_count = upsample_count - 1\n",
    "        if idx not in already_inserted:\n",
    "            already_inserted.append(idx)\n",
    "            img_paths.append(img_paths[idx])\n",
    "            labels.append(labels[idx])\n",
    "            count = count + 1\n",
    "            additional_data.append(additional_data[idx])\n",
    "\n",
    "print(len(additional_data))\n",
    "print(count)\n",
    "print(len(labels))\n",
    "#print(labels[:10])\n",
    "#print(img_paths[:5])\n",
    "\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    input_img = nib.load(path).get_fdata()\n",
    "    return input_img\n",
    "\n",
    "def min_max_normalize(image, new_min=0, new_max=1):\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    normalized_image = (image - min_val) / (max_val - min_val) * (new_max - new_min) + new_min\n",
    "    return normalized_image\n",
    "\n",
    "def separate_coronal_slices_around(img, slice_number, slices_count):\n",
    "    slices = []\n",
    "    for slice_no in range(slice_number - slices_count, slice_number + slices_count + 1):\n",
    "        slice = np.rot90(img[:, slice_no, :], k=2)\n",
    "        slice = min_max_normalize(slice)\n",
    "        slices.append(slice) # coronal\n",
    "    return slices\n",
    "\n",
    "class ADNI1_Dataset(Dataset):\n",
    "    def __init__(self, img_paths, additional_data, labels, label_dict, input_shapes):\n",
    "        self.img_paths = img_paths\n",
    "        self.additional_data = additional_data\n",
    "        self.labels = labels\n",
    "        self.label_dict = label_dict\n",
    "        self.input_shapes = input_shapes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = read_image(self.img_paths[idx])\n",
    "        coronal_slices = separate_coronal_slices_around(img, self.input_shapes[img.shape], 0)\n",
    "        coronal_slices = torch.tensor(coronal_slices, dtype=torch.float)\n",
    "        return coronal_slices, torch.tensor(self.additional_data[idx]), self.label_dict[self.labels[idx]]\n",
    "\n",
    "label_dict = {\n",
    "    \"CN\": 0,\n",
    "    \"AD\": 1,\n",
    "}\n",
    "\n",
    "dataset = ADNI1_Dataset(img_paths, additional_data, labels, label_dict, input_shapes)\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "dev_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - dev_size\n",
    "\n",
    "train_data, dev_data, test_data = random_split(dataset, [train_size, dev_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "dev_loader = DataLoader(dev_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "From models/Resnet module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import models.ResNet as RN\n",
    "_ = importlib.reload(RN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (fc2): Linear(in_features=2050, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(label_dict.keys())\n",
    "save_path = \"model_resnet.pth\"\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RN.ResNet101(device, num_classes)\n",
    "\n",
    "model.conv1 = torch.nn.Conv2d(1, model.conv1.out_channels, kernel_size=model.conv1.kernel_size, stride=model.conv1.stride, padding=model.conv1.padding, bias=model.conv1.bias)\n",
    "model.fc2 = torch.nn.Linear(in_features=model.fc2.in_features, out_features=2, bias=True)\n",
    "\n",
    "# if os.path.exists(save_path):\n",
    "#     print(f\"found saved state at: {save_path}\")\n",
    "#     checkpoint = torch.load(save_path)\n",
    "#     model.load_state_dict(checkpoint['model_state_dict'])  \n",
    "\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=514, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(label_dict.keys())\n",
    "save_path = \"weights/model_resnet.pth\"\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RN.ResNet18(device, num_classes)\n",
    "\n",
    "model.conv1 = torch.nn.Conv2d(1, model.conv1.out_channels, kernel_size=model.conv1.kernel_size, stride=model.conv1.stride, padding=model.conv1.padding, bias=model.conv1.bias)\n",
    "model.fc2 = torch.nn.Linear(in_features=model.fc2.in_features, out_features=2, bias=True)\n",
    "\n",
    "# if os.path.exists(save_path):\n",
    "#     print(f\"found saved state at: {save_path}\")\n",
    "#     checkpoint = torch.load(save_path)\n",
    "#     model.load_state_dict(checkpoint['model_state_dict'])  \n",
    "\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters for training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses = []\n",
    "dev_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[206.   9.]\n",
      " [ 19. 186.]]\n",
      "train loss = 0.17628375653709685, acc = 0.9218750596046448\n",
      "[[33. 11.]\n",
      " [ 6. 40.]]\n",
      "dev loss = 0.47470871607462567, accuracy = 0.8133012652397156\n",
      "new best acc: 0.8133012652397156\n",
      "\n",
      "epoch = 2/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[200.  15.]\n",
      " [ 13. 192.]]\n",
      "train loss = 0.2297774345747062, acc = 0.9375000596046448\n",
      "[[41.  3.]\n",
      " [12. 34.]]\n",
      "dev loss = 0.45753683646519977, accuracy = 0.834134578704834\n",
      "new best acc: 0.834134578704834\n",
      "\n",
      "epoch = 3/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[196.  19.]\n",
      " [ 23. 182.]]\n",
      "train loss = 0.30608523956366945, acc = 0.8750000596046448\n",
      "[[34. 10.]\n",
      " [10. 36.]]\n",
      "dev loss = 0.6001102228959402, accuracy = 0.7820512652397156\n",
      "\n",
      "epoch = 4/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[205.  10.]\n",
      " [ 28. 177.]]\n",
      "train loss = 0.23827754812581198, acc = 0.8995535969734192\n",
      "[[33. 11.]\n",
      " [ 8. 38.]]\n",
      "dev loss = 0.4656151831150055, accuracy = 0.7852563858032227\n",
      "\n",
      "epoch = 5/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[204.  11.]\n",
      " [ 17. 188.]]\n",
      "train loss = 0.1997927696044956, acc = 0.9375000596046448\n",
      "[[36.  8.]\n",
      " [10. 36.]]\n",
      "dev loss = 0.576451708873113, accuracy = 0.8100962042808533\n",
      "\n",
      "epoch = 6/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[209.   6.]\n",
      " [ 13. 192.]]\n",
      "train loss = 0.14923837913998536, acc = 0.941964328289032\n",
      "[[36.  8.]\n",
      " [ 7. 39.]]\n",
      "dev loss = 0.5922568837801615, accuracy = 0.8365384936332703\n",
      "new best acc: 0.8365384936332703\n",
      "\n",
      "epoch = 7/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[197.  18.]\n",
      " [ 14. 191.]]\n",
      "train loss = 0.2290928339851754, acc = 0.9285714626312256\n",
      "[[38.  6.]\n",
      " [13. 33.]]\n",
      "dev loss = 0.5603162944316864, accuracy = 0.7900640964508057\n",
      "\n",
      "epoch = 8/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[211.   4.]\n",
      " [ 13. 192.]]\n",
      "train loss = 0.11779605929872819, acc = 0.9620535969734192\n",
      "[[36.  8.]\n",
      " [ 8. 38.]]\n",
      "dev loss = 0.563722292582194, accuracy = 0.8189103007316589\n",
      "\n",
      "epoch = 9/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  6. 199.]]\n",
      "train loss = 0.14689407670604332, acc = 0.9553571939468384\n",
      "[[36.  8.]\n",
      " [ 9. 37.]]\n",
      "dev loss = 0.5815684199333191, accuracy = 0.8157051801681519\n",
      "\n",
      "epoch = 10/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[191.  24.]\n",
      " [ 13. 192.]]\n",
      "train loss = 0.2175827513315848, acc = 0.9017857313156128\n",
      "[[36.  8.]\n",
      " [12. 34.]]\n",
      "dev loss = 0.7409978906313578, accuracy = 0.7772436141967773\n",
      "\n",
      "epoch = 11/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[191.  24.]\n",
      " [ 22. 183.]]\n",
      "train loss = 0.26175897089498384, acc = 0.8973214626312256\n",
      "[[36.  8.]\n",
      " [15. 31.]]\n",
      "dev loss = 0.6555894017219543, accuracy = 0.7483974695205688\n",
      "\n",
      "epoch = 12/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[208.   7.]\n",
      " [ 13. 192.]]\n",
      "train loss = 0.12083585766543235, acc = 0.9553571939468384\n",
      "[[34. 10.]\n",
      " [ 6. 40.]]\n",
      "dev loss = 0.49080916742483777, accuracy = 0.8309295177459717\n",
      "\n",
      "epoch = 13/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[213.   2.]\n",
      " [  5. 200.]]\n",
      "train loss = 0.07450611224131924, acc = 0.9843750596046448\n",
      "[[35.  9.]\n",
      " [ 9. 37.]]\n",
      "dev loss = 0.5919704536596934, accuracy = 0.802884578704834\n",
      "\n",
      "epoch = 14/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  9. 196.]]\n",
      "train loss = 0.07716577273926564, acc = 0.9799107313156128\n",
      "[[38.  6.]\n",
      " [11. 35.]]\n",
      "dev loss = 0.6253328224023184, accuracy = 0.8108974695205688\n",
      "\n",
      "epoch = 15/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[214.   1.]\n",
      " [  3. 202.]]\n",
      "train loss = 0.054213065787085464, acc = 0.9910714626312256\n",
      "[[34. 10.]\n",
      " [ 8. 38.]]\n",
      "dev loss = 0.5923950473467509, accuracy = 0.7956730723381042\n",
      "\n",
      "epoch = 16/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[214.   1.]\n",
      " [  4. 201.]]\n",
      "train loss = 0.05045311638553228, acc = 0.988839328289032\n",
      "[[35.  9.]\n",
      " [ 8. 38.]]\n",
      "dev loss = 0.696636512875557, accuracy = 0.8060897588729858\n",
      "\n",
      "epoch = 17/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  3. 202.]]\n",
      "train loss = 0.03744879351662738, acc = 0.9933035969734192\n",
      "[[33. 11.]\n",
      " [10. 36.]]\n",
      "dev loss = 0.8182573715845743, accuracy = 0.7668269872665405\n",
      "\n",
      "epoch = 18/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  3. 202.]]\n",
      "train loss = 0.0380499600100198, acc = 0.9933035969734192\n",
      "[[33. 11.]\n",
      " [ 9. 37.]]\n",
      "dev loss = 0.7949919104576111, accuracy = 0.7796474695205688\n",
      "\n",
      "epoch = 19/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  3. 202.]]\n",
      "train loss = 0.03921846440061927, acc = 0.9933035969734192\n",
      "[[35.  9.]\n",
      " [ 9. 37.]]\n",
      "dev loss = 0.7067883610725403, accuracy = 0.8052884936332703\n",
      "\n",
      "epoch = 20/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  3. 202.]]\n",
      "train loss = 0.03621800882475717, acc = 0.9933035969734192\n",
      "[[37.  7.]\n",
      " [ 9. 37.]]\n",
      "dev loss = 0.7557567556699117, accuracy = 0.8189103007316589\n",
      "\n",
      "epoch = 21/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  3. 202.]]\n",
      "train loss = 0.04552297410555184, acc = 0.9933035969734192\n",
      "[[35.  9.]\n",
      " [ 8. 38.]]\n",
      "dev loss = 0.8329349358876547, accuracy = 0.8060897588729858\n",
      "\n",
      "epoch = 22/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[207.   8.]\n",
      " [  6. 199.]]\n",
      "train loss = 0.0998539902003748, acc = 0.9531250596046448\n",
      "[[35.  9.]\n",
      " [14. 32.]]\n",
      "dev loss = 0.8507355451583862, accuracy = 0.7435897588729858\n",
      "\n",
      "epoch = 23/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[211.   4.]\n",
      " [ 17. 188.]]\n",
      "train loss = 0.1433938013921891, acc = 0.9531250596046448\n",
      "[[33. 11.]\n",
      " [ 9. 37.]]\n",
      "dev loss = 0.9882651964823405, accuracy = 0.7820512652397156\n",
      "\n",
      "epoch = 24/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[211.   4.]\n",
      " [  8. 197.]]\n",
      "train loss = 0.09705533366650343, acc = 0.973214328289032\n",
      "[[35.  9.]\n",
      " [ 7. 39.]]\n",
      "dev loss = 0.6203517119089762, accuracy = 0.8165063858032227\n",
      "\n",
      "epoch = 25/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[213.   2.]\n",
      " [  4. 201.]]\n",
      "train loss = 0.048408012970217636, acc = 0.9866071939468384\n",
      "[[36.  8.]\n",
      " [ 8. 38.]]\n",
      "dev loss = 0.7053976953029633, accuracy = 0.8213140964508057\n",
      "\n",
      "epoch = 26/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  4. 201.]]\n",
      "train loss = 0.05396228050813079, acc = 0.9910714626312256\n",
      "[[34. 10.]\n",
      " [11. 35.]]\n",
      "dev loss = 0.8307786484559377, accuracy = 0.7668269872665405\n",
      "\n",
      "epoch = 27/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[210.   5.]\n",
      " [  5. 200.]]\n",
      "train loss = 0.1197546291431146, acc = 0.9620535969734192\n",
      "[[33. 11.]\n",
      " [11. 35.]]\n",
      "dev loss = 1.053583025932312, accuracy = 0.7564103007316589\n",
      "\n",
      "epoch = 28/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[211.   4.]\n",
      " [ 13. 192.]]\n",
      "train loss = 0.1165638621231275, acc = 0.9620535969734192\n",
      "[[28. 16.]\n",
      " [10. 36.]]\n",
      "dev loss = 1.0736257036526997, accuracy = 0.7099359035491943\n",
      "\n",
      "epoch = 29/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[202.  13.]\n",
      " [  9. 196.]]\n",
      "train loss = 0.11001587486160654, acc = 0.9508929252624512\n",
      "[[36.  8.]\n",
      " [13. 33.]]\n",
      "dev loss = 0.9622886776924133, accuracy = 0.7668269872665405\n",
      "\n",
      "epoch = 30/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[214.   1.]\n",
      " [  8. 197.]]\n",
      "train loss = 0.08789654122665524, acc = 0.9799107313156128\n",
      "[[34. 10.]\n",
      " [ 9. 37.]]\n",
      "dev loss = 0.867306669553121, accuracy = 0.7900640964508057\n",
      "\n",
      "epoch = 31/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[210.   5.]\n",
      " [  2. 203.]]\n",
      "train loss = 0.07133783446624875, acc = 0.9843750596046448\n",
      "[[37.  7.]\n",
      " [ 8. 38.]]\n",
      "dev loss = 0.8381492296854655, accuracy = 0.8365384936332703\n",
      "\n",
      "epoch = 32/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  4. 201.]]\n",
      "train loss = 0.04649908133848969, acc = 0.9910714626312256\n",
      "[[36.  8.]\n",
      " [14. 32.]]\n",
      "dev loss = 0.938636839389801, accuracy = 0.7564103007316589\n",
      "\n",
      "epoch = 33/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  2. 203.]]\n",
      "train loss = 0.030942709850413457, acc = 0.9955357313156128\n",
      "[[34. 10.]\n",
      " [11. 35.]]\n",
      "dev loss = 1.0250440835952759, accuracy = 0.7644230723381042\n",
      "\n",
      "epoch = 34/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[214.   1.]\n",
      " [  1. 204.]]\n",
      "train loss = 0.041347741415458064, acc = 0.9955357313156128\n",
      "[[35.  9.]\n",
      " [10. 36.]]\n",
      "dev loss = 0.945122500260671, accuracy = 0.7876603007316589\n",
      "\n",
      "epoch = 35/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  3. 202.]]\n",
      "train loss = 0.05933590765510287, acc = 0.9776785969734192\n",
      "[[29. 15.]\n",
      " [ 8. 38.]]\n",
      "dev loss = 1.3232029279073079, accuracy = 0.7483974695205688\n",
      "\n",
      "epoch = 36/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[196.  19.]\n",
      " [ 16. 189.]]\n",
      "train loss = 0.3295023799208658, acc = 0.9062500596046448\n",
      "[[36.  8.]\n",
      " [11. 35.]]\n",
      "dev loss = 0.7847975691159567, accuracy = 0.7924679517745972\n",
      "\n",
      "epoch = 37/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[195.  20.]\n",
      " [  8. 197.]]\n",
      "train loss = 0.22913158684968948, acc = 0.9218750596046448\n",
      "[[35.  9.]\n",
      " [13. 33.]]\n",
      "dev loss = 1.1695107022921245, accuracy = 0.7564103007316589\n",
      "\n",
      "epoch = 38/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[205.  10.]\n",
      " [ 15. 190.]]\n",
      "train loss = 0.1550455054135195, acc = 0.9441964626312256\n",
      "[[30. 14.]\n",
      " [12. 34.]]\n",
      "dev loss = 1.0970820387204487, accuracy = 0.7147436141967773\n",
      "\n",
      "epoch = 39/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[211.   4.]\n",
      " [  9. 196.]]\n",
      "train loss = 0.110596513508686, acc = 0.9553571939468384\n",
      "[[30. 14.]\n",
      " [ 8. 38.]]\n",
      "dev loss = 0.7959733406702677, accuracy = 0.7588140964508057\n",
      "\n",
      "epoch = 40/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[212.   3.]\n",
      " [ 11. 194.]]\n",
      "train loss = 0.1055397665394204, acc = 0.9687500596046448\n",
      "[[33. 11.]\n",
      " [ 5. 41.]]\n",
      "dev loss = 0.7162889242172241, accuracy = 0.8213140964508057\n",
      "\n",
      "epoch = 41/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[209.   6.]\n",
      " [  2. 203.]]\n",
      "train loss = 0.06804202936057534, acc = 0.9821429252624512\n",
      "[[37.  7.]\n",
      " [ 8. 38.]]\n",
      "dev loss = 0.6427124738693237, accuracy = 0.834134578704834\n",
      "\n",
      "epoch = 42/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[209.   6.]\n",
      " [  3. 202.]]\n",
      "train loss = 0.061825740932753045, acc = 0.9799107313156128\n",
      "[[39.  5.]\n",
      " [ 7. 39.]]\n",
      "dev loss = 0.5996980220079422, accuracy = 0.8677884936332703\n",
      "new best acc: 0.8677884936332703\n",
      "\n",
      "epoch = 43/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[214.   1.]\n",
      " [  2. 203.]]\n",
      "train loss = 0.07315415992135448, acc = 0.9776785969734192\n",
      "[[39.  5.]\n",
      " [11. 35.]]\n",
      "dev loss = 0.8296165068944296, accuracy = 0.8141025900840759\n",
      "\n",
      "epoch = 44/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[210.   5.]\n",
      " [ 13. 192.]]\n",
      "train loss = 0.24673598618911846, acc = 0.9441964626312256\n",
      "[[34. 10.]\n",
      " [10. 36.]]\n",
      "dev loss = 0.7797070741653442, accuracy = 0.7772436141967773\n",
      "\n",
      "epoch = 45/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[207.   8.]\n",
      " [ 23. 182.]]\n",
      "train loss = 0.19252410610871656, acc = 0.9151785969734192\n",
      "[[32. 12.]\n",
      " [ 5. 41.]]\n",
      "dev loss = 0.6007846544186274, accuracy = 0.8036859035491943\n",
      "\n",
      "epoch = 46/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  7. 198.]]\n",
      "train loss = 0.07776931676614497, acc = 0.9843750596046448\n",
      "[[35.  9.]\n",
      " [ 9. 37.]]\n",
      "dev loss = 0.7473028798898061, accuracy = 0.7884615659713745\n",
      "\n",
      "epoch = 47/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[213.   2.]\n",
      " [  2. 203.]]\n",
      "train loss = 0.04512010351754725, acc = 0.9910714626312256\n",
      "[[34. 10.]\n",
      " [ 6. 40.]]\n",
      "dev loss = 0.626011848449707, accuracy = 0.8189103007316589\n",
      "\n",
      "epoch = 48/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[214.   1.]\n",
      " [  1. 204.]]\n",
      "train loss = 0.02577181250256087, acc = 0.9955357313156128\n",
      "[[32. 12.]\n",
      " [ 7. 39.]]\n",
      "dev loss = 0.830366184314092, accuracy = 0.797275722026825\n",
      "\n",
      "epoch = 49/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  2. 203.]]\n",
      "train loss = 0.024778764079590992, acc = 0.9955357313156128\n",
      "[[35.  9.]\n",
      " [ 7. 39.]]\n",
      "dev loss = 0.8933302958806356, accuracy = 0.8165063858032227\n",
      "\n",
      "epoch = 50/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  1. 204.]]\n",
      "train loss = 0.02264504344202578, acc = 0.9977679252624512\n",
      "[[34. 10.]\n",
      " [ 7. 39.]]\n",
      "dev loss = 0.9214649796485901, accuracy = 0.8036859035491943\n",
      "\n",
      "epoch = 51/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  1. 204.]]\n",
      "train loss = 0.019176740149435188, acc = 0.9977679252624512\n",
      "[[32. 12.]\n",
      " [ 8. 38.]]\n",
      "dev loss = 1.0295737634102504, accuracy = 0.7772436141967773\n",
      "\n",
      "epoch = 52/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  1. 204.]]\n",
      "train loss = 0.018429611144321307, acc = 0.9977679252624512\n",
      "[[33. 11.]\n",
      " [ 7. 39.]]\n",
      "dev loss = 0.8074951271216074, accuracy = 0.8052884936332703\n",
      "\n",
      "epoch = 53/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  1. 204.]]\n",
      "train loss = 0.018359861852202033, acc = 0.9977679252624512\n",
      "[[35.  9.]\n",
      " [ 8. 38.]]\n",
      "dev loss = 0.9112326900164286, accuracy = 0.8036859035491943\n",
      "\n",
      "epoch = 54/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  1. 204.]]\n",
      "train loss = 0.017383965929704055, acc = 0.9977679252624512\n",
      "[[34. 10.]\n",
      " [ 6. 40.]]\n",
      "dev loss = 0.8537317911783854, accuracy = 0.8261218070983887\n",
      "\n",
      "epoch = 55/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  1. 204.]]\n",
      "train loss = 0.0188451001221048, acc = 0.9977679252624512\n",
      "[[36.  8.]\n",
      " [ 7. 39.]]\n",
      "dev loss = 0.8685212930043539, accuracy = 0.8317307829856873\n",
      "\n",
      "epoch = 56/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[214.   1.]\n",
      " [  1. 204.]]\n",
      "train loss = 0.03082037457664098, acc = 0.9799107313156128\n",
      "[[34. 10.]\n",
      " [ 7. 39.]]\n",
      "dev loss = 0.7460311849912008, accuracy = 0.8084936141967773\n",
      "\n",
      "epoch = 57/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  6. 199.]]\n",
      "train loss = 0.062327888228797486, acc = 0.9866071939468384\n",
      "[[33. 11.]\n",
      " [11. 35.]]\n",
      "dev loss = 0.9459526141484579, accuracy = 0.7516025900840759\n",
      "\n",
      "epoch = 58/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[213.   2.]\n",
      " [  3. 202.]]\n",
      "train loss = 0.16425433409001147, acc = 0.957589328289032\n",
      "[[33. 11.]\n",
      " [ 8. 38.]]\n",
      "dev loss = 0.9596084554990133, accuracy = 0.7876603007316589\n",
      "\n",
      "epoch = 59/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[203.  12.]\n",
      " [  5. 200.]]\n",
      "train loss = 0.12375751590090138, acc = 0.9620535969734192\n",
      "[[35.  9.]\n",
      " [12. 34.]]\n",
      "dev loss = 1.2248634894688923, accuracy = 0.7668269872665405\n",
      "\n",
      "epoch = 60/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  9. 196.]]\n",
      "train loss = 0.06360422357517694, acc = 0.9799107313156128\n",
      "[[34. 10.]\n",
      " [ 8. 38.]]\n",
      "dev loss = 0.9329334398110708, accuracy = 0.8076924085617065\n",
      "\n",
      "epoch = 61/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[213.   2.]\n",
      " [  1. 204.]]\n",
      "train loss = 0.03158582534108843, acc = 0.9933035969734192\n",
      "[[34. 10.]\n",
      " [ 8. 38.]]\n",
      "dev loss = 0.851295272509257, accuracy = 0.7956730723381042\n",
      "\n",
      "epoch = 62/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[214.   1.]\n",
      " [  2. 203.]]\n",
      "train loss = 0.02558343528237726, acc = 0.9933035969734192\n",
      "[[34. 10.]\n",
      " [ 7. 39.]]\n",
      "dev loss = 0.9793064395586649, accuracy = 0.8133012652397156\n",
      "\n",
      "epoch = 63/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  1. 204.]]\n",
      "train loss = 0.019950017233246138, acc = 0.9977679252624512\n",
      "[[35.  9.]\n",
      " [11. 35.]]\n",
      "dev loss = 1.0179309248924255, accuracy = 0.7796474695205688\n",
      "\n",
      "epoch = 64/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  1. 204.]]\n",
      "train loss = 0.019551681986610805, acc = 0.9977679252624512\n",
      "[[36.  8.]\n",
      " [ 9. 37.]]\n",
      "dev loss = 1.0008340080579121, accuracy = 0.8133012652397156\n",
      "\n",
      "epoch = 65/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  1. 204.]]\n",
      "train loss = 0.01809167007117399, acc = 0.9977679252624512\n",
      "[[35.  9.]\n",
      " [ 9. 37.]]\n",
      "dev loss = 0.9166400035222372, accuracy = 0.7980769872665405\n",
      "\n",
      "epoch = 66/100\n",
      "batch id = 0\n",
      "batch id = 10\n",
      "[[215.   0.]\n",
      " [  1. 204.]]\n",
      "train loss = 0.017554678239061365, acc = 0.9977679252624512\n",
      "[[35.  9.]\n",
      " [ 8. 38.]]\n",
      "dev loss = 0.9391047358512878, accuracy = 0.8157051801681519\n",
      "\n",
      "epoch = 67/100\n",
      "batch id = 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[165], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m---> 12\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prev_best_eval_acc = 0.7\n",
    "version = 7\n",
    "iter = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"epoch = {epoch + 1}/{num_epochs}\")\n",
    "    train_running_loss = 0\n",
    "    n = 0\n",
    "    # don't put (data, labels) here instead of data. it botches the self.labels in the loader for some reason\n",
    "    acc = 0\n",
    "    conf_matrix = np.zeros((2, 2))\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        n = n + 1\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"batch id = {batch_idx}\")    \n",
    "            pass\n",
    "        imgs, additional_data, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "        outputs = model(imgs, additional_data)\n",
    "\n",
    "        optimizer.zero_grad() # cleans gradients\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward() # computes gradients\n",
    "        optimizer.step() # applies gradient modifications\n",
    "\n",
    "        train_running_loss += loss.item()\n",
    "        acc = acc + torch.sum(torch.argmax(outputs, dim=1) == labels) / len(labels)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        conf_matrix += sklearn.metrics.confusion_matrix(labels.cpu().numpy(), preds.cpu().numpy(), labels=np.arange(2))\n",
    "    \n",
    "    print(conf_matrix)\n",
    "    train_losses.append(train_running_loss / n)\n",
    "    print(f\"train loss = {train_running_loss / n}, acc = {acc / n}\")\n",
    "\n",
    "\n",
    "    dev_running_loss = 0\n",
    "    conf_matrix = np.zeros((2, 2))\n",
    "    n = 0\n",
    "    acc = 0\n",
    "    for i, data in enumerate(dev_loader):\n",
    "        # if i % 10 == 0:\n",
    "        #     print(f\"batch_id = {i}\")\n",
    "        n = n + 1\n",
    "        imgs, additional_data, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "        \n",
    "        outputs = model(imgs, additional_data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        dev_running_loss += loss.item()    \n",
    "        # loss.backward()\n",
    "\n",
    "        acc = acc + torch.sum(torch.argmax(outputs, dim=1) == labels) / len(labels)\n",
    "        conf_matrix += sklearn.metrics.confusion_matrix(labels.cpu().numpy(), torch.argmax(outputs, dim=1).cpu().numpy(), labels=np.arange(2))\n",
    "        \n",
    "    print(conf_matrix)\n",
    "    print(f\"dev loss = {dev_running_loss / n}, accuracy = {acc / n}\")\n",
    "    dev_losses.append(dev_running_loss / n)\n",
    "    if acc / n > prev_best_eval_acc:\n",
    "        print(f\"new best acc: {acc / n}\")\n",
    "        version = version + 1\n",
    "        prev_best_eval_acc = acc / n\n",
    "        dt_save_path = f\"weights/model_resnet_{iter}_{version}.pth\"\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'loss': loss\n",
    "        }, dt_save_path)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_save_path = 'model_resnet_best.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'loss': loss\n",
    "}, pt_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found saved state at: model_resnet_best.pth\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(label_dict.keys())\n",
    "# save_path = \"model_resnet_17.pth\"\n",
    "save_path = \"model_resnet_best.pth\"\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RN.ResNet18(device, num_classes)\n",
    "\n",
    "model.conv1 = torch.nn.Conv2d(1, model.conv1.out_channels, kernel_size=model.conv1.kernel_size, stride=model.conv1.stride, padding=model.conv1.padding, bias=model.conv1.bias)\n",
    "model.fc2 = torch.nn.Linear(in_features=model.fc2.in_features, out_features=2, bias=True)\n",
    "\n",
    "if os.path.exists(save_path):\n",
    "    print(f\"found saved state at: {save_path}\")\n",
    "    checkpoint = torch.load(save_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])  \n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Facultate\\anul_3\\ELL\\Code\\Datasets\\ADNI\\ADNI1\\InputImages\\002_S_0816__2006-08-30.nii\n",
      "(0, 71)\n",
      "AD\n"
     ]
    }
   ],
   "source": [
    "idx = 20\n",
    "print(test_data.dataset.img_paths[idx])\n",
    "print(test_data.dataset.additional_data[idx])\n",
    "print(test_data.dataset.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id = 0\n",
      "[[36.  5.]\n",
      " [ 4. 45.]]\n",
      "eval loss = 0.734869917233785, accuracy = 0.8942307829856873\n",
      "sensitivity = 0.95427059712774, specificity = 0.8910956252419667, AUC = 0.896131354026091\n"
     ]
    }
   ],
   "source": [
    "test_running_loss = 0\n",
    "conf_matrix = np.zeros((2, 2))\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "n = 0\n",
    "acc = 0\n",
    "sens = 0\n",
    "spec = 0\n",
    "auc = 0\n",
    "for i, data in enumerate(test_loader):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"batch_id = {i}\")\n",
    "    n = n + 1\n",
    "    imgs, additional_data, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "    \n",
    "    outputs = model(imgs, additional_data)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    test_running_loss += loss.item()    \n",
    "    \n",
    "    conf_matrix += sklearn.metrics.confusion_matrix(labels.cpu().numpy(), torch.argmax(outputs, dim=1).cpu().numpy(), labels=np.arange(2))\n",
    "\n",
    "    TN = conf_matrix[0, 0]\n",
    "    FP = conf_matrix[0, 1]\n",
    "    FN = conf_matrix[1, 0]\n",
    "    TP = conf_matrix[1, 1]\n",
    "\n",
    "    sens = sens + TP / (TP + FN)  # True Positive Rate (TPR)\n",
    "    spec = spec + TN / (TN + FP)  # True Negative Rate (TNR)\n",
    "    auc = auc + sklearn.metrics.roc_auc_score(labels.cpu().numpy(), torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "    acc = acc + torch.sum(torch.argmax(outputs, dim=1) == labels) / len(labels)\n",
    "\n",
    "print(conf_matrix)\n",
    "print(f\"eval loss = {test_running_loss / n}, accuracy = {acc / n}\")\n",
    "print(f\"sensitivity = {sens / n}, specificity = {spec / n}, AUC = {auc / n}\")\n",
    "test_losses.append(test_running_loss / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "with open(\"text_2.txt\", 'w') as file:\n",
    "    for loss in train_losses:\n",
    "        file.write(str(loss) + \"\\n\")\n",
    "# _ = plt.yticks(list(range(0,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_train_losses = []\n",
    "with open(\"text.txt\", 'r') as file:\n",
    "    for line in file:\n",
    "        _train_losses.append(float(line.strip()))\n",
    "plt.plot(_train_losses)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
