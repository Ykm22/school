{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Facultate\\anul_3\\ELL\\Code\\Datasets\\ADNI\\ADNI1\n",
      "d:\\Facultate\\anul_3\\ELL\\Code\\Datasets\\ADNI\\ADNI1\\Images\n",
      "d:\\Facultate\\anul_3\\ELL\\Code\\Datasets\\ADNI\\ADNI1\\SegmentationMasks\n",
      "d:\\Facultate\\anul_3\\ELL\\Code\\Datasets\\ADNI\\ADNI1\\ADNI1_T1_Imgs_CN-MCI-AD_5_18_2024.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = Path(os.getcwd()) / \"Datasets\" / \"ADNI\" / \"ADNI1\"\n",
    "print(dataset_dir)\n",
    "\n",
    "imgs_dir = dataset_dir / \"Images\"\n",
    "masks_dir = dataset_dir / \"SegmentationMasks\"\n",
    "store_dir = dataset_dir / \"InputImages\"\n",
    "input_dir = store_dir\n",
    "\n",
    "print(imgs_dir)\n",
    "print(masks_dir)\n",
    "\n",
    "csv_files = dataset_dir.glob(\"**/*.csv\")\n",
    "for csv_file in csv_files:\n",
    "    csv_data = csv_file\n",
    "    \n",
    "print(csv_data)\n",
    "df = pd.read_csv(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Acq Date</th>\n",
       "      <th>Format</th>\n",
       "      <th>Downloaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2720 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Image Data ID  Subject  Group    Sex    Age  Visit  Modality  \\\n",
       "0             False    False  False  False  False  False     False   \n",
       "1             False    False  False  False  False  False     False   \n",
       "2             False    False  False  False  False  False     False   \n",
       "3             False    False  False  False  False  False     False   \n",
       "4             False    False  False  False  False  False     False   \n",
       "...             ...      ...    ...    ...    ...    ...       ...   \n",
       "2715          False    False  False  False  False  False     False   \n",
       "2716          False    False  False  False  False  False     False   \n",
       "2717          False    False  False  False  False  False     False   \n",
       "2718          False    False  False  False  False  False     False   \n",
       "2719          False    False  False  False  False  False     False   \n",
       "\n",
       "      Description   Type  Acq Date  Format  Downloaded  \n",
       "0           False  False     False   False       False  \n",
       "1           False  False     False   False       False  \n",
       "2           False  False     False   False       False  \n",
       "3           False  False     False   False       False  \n",
       "4           False  False     False   False       False  \n",
       "...           ...    ...       ...     ...         ...  \n",
       "2715        False  False     False   False       False  \n",
       "2716        False  False     False   False       False  \n",
       "2717        False  False     False   False       False  \n",
       "2718        False  False     False   False       False  \n",
       "2719        False  False     False   False       False  \n",
       "\n",
       "[2720 rows x 12 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-18.3803,  13.6432]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-18.3952,  13.7174]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-18.3952,  13.7174]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-18.3952,  13.7174]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-16.1119,  12.3006]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "df.where(df[\"Group\"] == \"AD\").notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import models.ResNet as RN\n",
    "_ = importlib.reload(RN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found saved state at: model_resnet_best.pth\n"
     ]
    }
   ],
   "source": [
    "label_dict = {\n",
    "    \"CN\": 0,\n",
    "    \"AD\": 1,\n",
    "}\n",
    "\n",
    "num_classes = len(label_dict.keys())\n",
    "save_path = \"model_resnet_best.pth\"\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RN.ResNet18(device, num_classes)\n",
    "\n",
    "model.conv1 = torch.nn.Conv2d(1, model.conv1.out_channels, kernel_size=model.conv1.kernel_size, stride=model.conv1.stride, padding=model.conv1.padding, bias=model.conv1.bias)\n",
    "model.fc2 = torch.nn.Linear(in_features=model.fc2.in_features, out_features=2, bias=True)\n",
    "\n",
    "if os.path.exists(save_path):\n",
    "    print(f\"found saved state at: {save_path}\")\n",
    "    checkpoint = torch.load(save_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])  \n",
    "\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7883\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7883/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 4.14.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\shutil.py\", line 825, in move\n",
      "    os.rename(src, real_dst)\n",
      "FileExistsError: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\stefa\\\\AppData\\\\Local\\\\Temp\\\\tmpr8_nur1b' -> 'C:\\\\Users\\\\stefa\\\\AppData\\\\Local\\\\Temp\\\\gradio\\\\66aa5b27a8fbc09f10e1e6372bf90789e8541ae3\\\\002_S_0295__2006-11-02.nii'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 408, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 84, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\applications.py\", line 116, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\cors.py\", line 91, in __call__\n",
      "    await self.simple_response(scope, receive, send, request_headers=headers)\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\cors.py\", line 146, in simple_response\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 62, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 55, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 44, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 746, in __call__\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 288, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 75, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 55, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 44, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 73, in app\n",
      "    await response(scope, receive, send)\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\responses.py\", line 156, in __call__\n",
      "    await self.background()\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\background.py\", line 43, in __call__\n",
      "    await task()\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\background.py\", line 28, in __call__\n",
      "    await run_in_threadpool(self.func, *self.args, **self.kwargs)\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\concurrency.py\", line 35, in run_in_threadpool\n",
      "    return await anyio.to_thread.run_sync(func, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\routes.py\", line 122, in move_uploaded_files_to_cache\n",
      "    shutil.move(file, dest)\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\shutil.py\", line 845, in move\n",
      "    copy_function(src, real_dst)\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\shutil.py\", line 436, in copy2\n",
      "    copyfile(src, dst, follow_symlinks=follow_symlinks)\n",
      "  File \"c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\shutil.py\", line 258, in copyfile\n",
      "    with open(dst, 'wb') as fdst:\n",
      "         ^^^^^^^^^^^^^^^\n",
      "OSError: [Errno 22] Invalid argument: 'C:\\\\Users\\\\stefa\\\\AppData\\\\Local\\\\Temp\\\\gradio\\\\66aa5b27a8fbc09f10e1e6372bf90789e8541ae3\\\\002_S_0295__2006-11-02.nii'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0, 85]], device='cuda:0')\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')\n",
      "tensor([[ 0, 71]], device='cuda:0')\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "input_shapes = {\n",
    "    (256, 256, 166) : 128,\n",
    "}\n",
    "\n",
    "labels = {\n",
    "    0: \"Cognitively Normal\",\n",
    "    1: \"Alzheimer's Disease\",\n",
    "}\n",
    "\n",
    "def read_image(path):\n",
    "    input_img = nib.load(path).get_fdata()\n",
    "    return input_img\n",
    "\n",
    "def min_max_normalize(image, new_min=0, new_max=1):\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    normalized_image = (image - min_val) / (max_val - min_val) * (new_max - new_min) + new_min\n",
    "    return normalized_image\n",
    "\n",
    "def separate_coronal_slices_around(img, slice_number, slices_count):\n",
    "    slices = []\n",
    "    for slice_no in range(slice_number - slices_count, slice_number + slices_count + 1):\n",
    "        slice = np.rot90(img[:, slice_no, :], k=2)\n",
    "        slice = min_max_normalize(slice)\n",
    "        slices.append(slice) # coronal\n",
    "    return slices\n",
    "\n",
    "def predict(file, age, sex):\n",
    "    img = read_image(file.name)\n",
    "    if img.shape not in input_shapes:\n",
    "        return \"Incorrect file dimensions, try another\"\n",
    "    coronal_slices = separate_coronal_slices_around(img, input_shapes[img.shape], 0)\n",
    "    coronal_slices = torch.tensor(coronal_slices, dtype=torch.float).to(device)\n",
    "\n",
    "    x = coronal_slices.unsqueeze(0)\n",
    "    y = torch.tensor((sex, age)).unsqueeze(0).to(device)\n",
    "    print(y)\n",
    "    print(x)\n",
    "    # print(x.shape, y.shape)\n",
    "    output = F.softmax(model(x, y), dim=1)\n",
    "    # print(output)\n",
    "    return labels[torch.argmax(output, dim=1).item()]\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=[\n",
    "        gr.File(label=\"Upload .nii file\"),\n",
    "        gr.Slider(1, 100, step=1, label='Age'),\n",
    "        gr.Radio(['Male', 'Female'], label='Sex', type='index')\n",
    "    ],\n",
    "    outputs='text',\n",
    "    title=\"Alzheimer's Disease prediction\"\n",
    ")\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
