{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7597e4-44d7-42ae-a1fd-8b3848b47d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import logging\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25990d36-8874-47f1-a8dc-62e214297dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc3a2a9b-5161-4377-b122-6ef68cbf8713",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.classes = None\n",
    "        self.mean = None\n",
    "        self.var = None\n",
    "        self.priors = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.classes = np.unique(y)\n",
    "        n_classes = len(self.classes)\n",
    "        \n",
    "        logger.info(f\"Starting training with {n_samples} samples, {n_features} features\")\n",
    "        logger.info(f\"Detected classes: {self.classes}\")\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.mean = np.zeros((n_classes, n_features))\n",
    "        self.var = np.zeros((n_classes, n_features))\n",
    "        self.priors = np.zeros(n_classes)\n",
    "        \n",
    "        # Calculate mean, variance, and prior for each class\n",
    "        for idx, c in enumerate(self.classes):\n",
    "            X_c = X[y == c]\n",
    "            self.mean[idx, :] = X_c.mean(axis=0)\n",
    "            self.var[idx, :] = X_c.var(axis=0)\n",
    "            self.priors[idx] = len(X_c) / n_samples\n",
    "            \n",
    "            logger.info(f\"Class {c} statistics:\")\n",
    "            logger.info(f\"- Prior probability: {self.priors[idx]:.3f}\")\n",
    "            logger.info(f\"- Mean range: [{self.mean[idx].min():.3f}, {self.mean[idx].max():.3f}]\")\n",
    "            logger.info(f\"- Variance range: [{self.var[idx].min():.3f}, {self.var[idx].max():.3f}]\")\n",
    "    \n",
    "    def _calculate_likelihood(self, X, mean, var):\n",
    "        # Calculate Gaussian probability density function\n",
    "        epsilon = 1e-10  # To avoid division by zero\n",
    "        exponent = -0.5 * np.square(X - mean) / (var + epsilon)\n",
    "        return np.sum(exponent - 0.5 * np.log(2 * np.pi * (var + epsilon)), axis=1)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        logger.info(f\"Predicting {n_samples} samples\")\n",
    "        \n",
    "        # Calculate likelihood for each class\n",
    "        posteriors = []\n",
    "        for idx in range(len(self.classes)):\n",
    "            likelihood = self._calculate_likelihood(X, self.mean[idx], self.var[idx])\n",
    "            posterior = likelihood + np.log(self.priors[idx])\n",
    "            posteriors.append(posterior)\n",
    "        \n",
    "        # Get class with highest posterior\n",
    "        posteriors = np.array(posteriors).T\n",
    "        predictions = np.argmax(posteriors, axis=1)\n",
    "        \n",
    "        logger.info(f\"Prediction complete\")\n",
    "        return self.classes[predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf709157-3412-4cee-b145-bc32327796e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 10:08:23,663 - INFO - Loading Breast Cancer Wisconsin dataset\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare the data\n",
    "logger.info(\"Loading Breast Cancer Wisconsin dataset\")\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99fb7b10-1bc9-4685-99a2-79e609796122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 10:08:39,038 - INFO - Train set size: 455, Test set size: 114\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "logger.info(f\"Train set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c6f85ac-321f-4382-80f7-2a7496bbedb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 10:08:48,225 - INFO - Data scaling complete\n"
     ]
    }
   ],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "logger.info(\"Data scaling complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99976af2-4fbb-401a-84c0-a2e3c1b73a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 10:08:58,834 - INFO - Training Naive Bayes classifier\n",
      "2024-11-21 10:08:58,837 - INFO - Starting training with 455 samples, 30 features\n",
      "2024-11-21 10:08:58,838 - INFO - Detected classes: [0 1]\n",
      "2024-11-21 10:08:58,840 - INFO - Class 0 statistics:\n",
      "2024-11-21 10:08:58,842 - INFO - - Prior probability: 0.371\n",
      "2024-11-21 10:08:58,843 - INFO - - Mean range: [-0.076, 1.026]\n",
      "2024-11-21 10:08:58,845 - INFO - - Variance range: [0.461, 1.911]\n",
      "2024-11-21 10:08:58,848 - INFO - Class 1 statistics:\n",
      "2024-11-21 10:08:58,848 - INFO - - Prior probability: 0.629\n",
      "2024-11-21 10:08:58,849 - INFO - - Mean range: [-0.606, 0.045]\n",
      "2024-11-21 10:08:58,850 - INFO - - Variance range: [0.036, 1.296]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "logger.info(\"Training Naive Bayes classifier\")\n",
    "nb_classifier = NaiveBayesClassifier()\n",
    "nb_classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e5485c1-a585-4daf-9a2b-7dab0bae6fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 10:09:25,214 - INFO - Making predictions on test set\n",
      "2024-11-21 10:09:25,217 - INFO - Predicting 114 samples\n",
      "2024-11-21 10:09:25,219 - INFO - Prediction complete\n",
      "2024-11-21 10:09:25,221 - INFO - Test set accuracy: 0.965\n",
      "2024-11-21 10:09:25,223 - INFO - Feature 'mean radius' importance: 1.486\n",
      "2024-11-21 10:09:25,224 - INFO - Feature 'mean texture' importance: 0.861\n",
      "2024-11-21 10:09:25,226 - INFO - Feature 'mean perimeter' importance: 1.515\n",
      "2024-11-21 10:09:25,228 - INFO - Feature 'mean area' importance: 1.439\n",
      "2024-11-21 10:09:25,230 - INFO - Feature 'mean smoothness' importance: 0.776\n",
      "2024-11-21 10:09:25,231 - INFO - Feature 'mean compactness' importance: 1.222\n",
      "2024-11-21 10:09:25,232 - INFO - Feature 'mean concavity' importance: 1.414\n",
      "2024-11-21 10:09:25,234 - INFO - Feature 'mean concave points' importance: 1.610\n",
      "2024-11-21 10:09:25,235 - INFO - Feature 'mean symmetry' importance: 0.720\n",
      "2024-11-21 10:09:25,236 - INFO - Feature 'mean fractal dimension' importance: 0.030\n",
      "2024-11-21 10:09:25,237 - INFO - Feature 'radius error' importance: 1.118\n",
      "2024-11-21 10:09:25,238 - INFO - Feature 'texture error' importance: 0.007\n",
      "2024-11-21 10:09:25,239 - INFO - Feature 'perimeter error' importance: 1.095\n",
      "2024-11-21 10:09:25,240 - INFO - Feature 'area error' importance: 1.070\n",
      "2024-11-21 10:09:25,242 - INFO - Feature 'smoothness error' importance: 0.120\n",
      "2024-11-21 10:09:25,243 - INFO - Feature 'compactness error' importance: 0.526\n",
      "2024-11-21 10:09:25,244 - INFO - Feature 'concavity error' importance: 0.447\n",
      "2024-11-21 10:09:25,246 - INFO - Feature 'concave points error' importance: 0.787\n",
      "2024-11-21 10:09:25,247 - INFO - Feature 'symmetry error' importance: 0.010\n",
      "2024-11-21 10:09:25,248 - INFO - Feature 'fractal dimension error' importance: 0.086\n",
      "2024-11-21 10:09:25,250 - INFO - Feature 'worst radius' importance: 1.586\n",
      "2024-11-21 10:09:25,251 - INFO - Feature 'worst texture' importance: 0.967\n",
      "2024-11-21 10:09:25,252 - INFO - Feature 'worst perimeter' importance: 1.604\n",
      "2024-11-21 10:09:25,253 - INFO - Feature 'worst area' importance: 1.496\n",
      "2024-11-21 10:09:25,254 - INFO - Feature 'worst smoothness' importance: 0.891\n",
      "2024-11-21 10:09:25,263 - INFO - Feature 'worst compactness' importance: 1.219\n",
      "2024-11-21 10:09:25,264 - INFO - Feature 'worst concavity' importance: 1.345\n",
      "2024-11-21 10:09:25,265 - INFO - Feature 'worst concave points' importance: 1.633\n",
      "2024-11-21 10:09:25,266 - INFO - Feature 'worst symmetry' importance: 0.911\n",
      "2024-11-21 10:09:25,267 - INFO - Feature 'worst fractal dimension' importance: 0.648\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "logger.info(\"Making predictions on test set\")\n",
    "y_pred = nb_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "logger.info(f\"Test set accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Print feature names and their importance\n",
    "feature_importance = np.abs(nb_classifier.mean[1] - nb_classifier.mean[0])\n",
    "for feature_name, importance in zip(data.feature_names, feature_importance):\n",
    "    logger.info(f\"Feature '{feature_name}' importance: {importance:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Environment",
   "language": "python",
   "name": "ml_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
